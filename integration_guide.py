#!/usr/bin/env python3
"""
ðŸŽ¯ MEVCUT KODUNUZA DECORATOR ENTEGRASYONU
========================================

Bu dosya, mevcut transcript pipeline'Ä±nÄ±za monitoring nasÄ±l entegre edeceÄŸinizi gÃ¶sterir.
"""

# ============================================================================
# 1. MEVCUT app/main.py DOSYANIZI GÃœNCELLEYÄ°N
# ============================================================================

"""
Ã–NCE (Mevcut main.py):

from fastapi import FastAPI, HTTPException
from app.schemas import TranscribeRequest, TranscribeResponse
from app.pipeline.pipeline import run_transcript_pipeline

app = FastAPI(title="Arya HI Transcript Extraction API")

@app.post("/transcribe", response_model=TranscribeResponse)
def transcribe_video(request: TranscribeRequest):
    try:
        result = run_transcript_pipeline(
            mp4_path=request.video_path,
            user_id=request.user_id,
            attendees=request.attendees,
            meeting_id=request.meeting_id
        )
        return {"json_output": result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
"""

# ============================================================================
# SONRA (Monitoring ile gÃ¼ncellenmiÅŸ main.py):
# ============================================================================

from fastapi import FastAPI, HTTPException
from app.schemas import TranscribeRequest, TranscribeResponse
from app.pipeline.pipeline import run_transcript_pipeline

# ðŸš€ SADECE BU IMPORT'U EKLEYÄ°N!
from transcript_monitoring import transcript_monitor, get_monitoring_stats, health_check

app = FastAPI(title="Arya HI Transcript Extraction API")

@app.get("/health")
def health_check_endpoint():
    return {"status": "healthy", "service": "transcript-api"}

# ðŸš€ YENÄ°: Monitoring health check endpoint
@app.get("/monitoring/health")
async def monitoring_health():
    """Monitoring sistem durumunu kontrol et."""
    health_status = await health_check()
    return health_status

# ðŸš€ YENÄ°: Monitoring statistics endpoint
@app.get("/monitoring/stats")
def monitoring_stats():
    """Monitoring istatistiklerini getir."""
    return get_monitoring_stats()

# ðŸš€ SADECE DECORATOR EKLEYÄ°N - BAÅžKA HÄ°Ã‡BÄ°R ÅžEY DEÄžÄ°ÅžMEDÄ°!
@app.post("/transcribe", response_model=TranscribeResponse)
@transcript_monitor(
    user_context=lambda request: request.user_id,
    session_context=lambda request: request.meeting_id,
    track_audio_metadata=True,
    send_to_vertex=True  # .env'de SEND_TO_VERTEX=true olduÄŸunda aktif
)
async def transcribe_video(request: TranscribeRequest):
    """
    Video transkript iÅŸlemi - ÅŸimdi otomatik monitoring ile!

    Decorator otomatik olarak:
    - Performance metrics toplar (latency, processing time)
    - User ID ve meeting ID'yi track eder
    - Background'da Vertex AI'ya gÃ¶nderir
    - Error handling yapar
    """
    try:
        # ðŸš€ MEVCUT KODUNUZ HÄ°Ã‡ DEÄžÄ°ÅžMEDÄ°!
        result = await run_transcript_pipeline_async(  # Async yaptÄ±k
            mp4_path=request.video_path,
            user_id=request.user_id,
            attendees=request.attendees,
            meeting_id=request.meeting_id
        )
        return {"json_output": result}
    except Exception as e:
        # Decorator otomatik olarak error'u track eder
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# 2. app/pipeline/pipeline.py DOSYANIZI GÃœNCELLEYÄ°N
# ============================================================================

"""
MEVCUT pipeline.py dosyanÄ±zda sadece ÅŸunlarÄ± yapÄ±n:

1. Import ekleyin:
"""

# DosyanÄ±n baÅŸÄ±na ekleyin:
from transcript_monitoring import transcript_monitor

"""
2. Ana fonksiyonu async yapÄ±n ve decorator ekleyin:
"""

# Ã–NCE:
# def run_transcript_pipeline(mp4_path: str, output_root: str = DEFAULT_OUTPUT_ROOT,
#                            user_id: str = "anonymous", attendees: Optional[List[str]] = None,
#                            meeting_id: Optional[str] = None) -> dict:

# SONRA:
@transcript_monitor(
    user_context=lambda *args, **kwargs: kwargs.get('user_id', 'anonymous'),
    session_context=lambda *args, **kwargs: kwargs.get('meeting_id'),
    track_audio_metadata=True,
    custom_config={
        "track_performance_metrics": True,
        "track_quality_metrics": True,
        "offline_mode": True  # Ä°lk test iÃ§in offline
    }
)
async def run_transcript_pipeline(mp4_path: str, output_root: str = None,
                                 user_id: str = "anonymous",
                                 attendees: Optional[List[str]] = None,
                                 meeting_id: Optional[str] = None) -> dict:
    """
    Åžimdi bu fonksiyon otomatik olarak:
    - Her Ã§aÄŸrÄ± iÃ§in unique request ID oluÅŸturur
    - Audio file metadata'sÄ±nÄ± toplar
    - Her aÅŸamanÄ±n sÃ¼resini Ã¶lÃ§er
    - User ve session bazÄ±nda analytics toplar
    - Background'da Vertex AI'ya gÃ¶nderir
    """

    # ðŸš€ MEVCUT KODUNUZ TAMAMEN AYNI KALIYOR!
    # Sadece async/await ekleyeceksiniz gerektiÄŸinde

    session_id = uuid4().hex
    # ... mevcut kodunuz ...

    return final_result


# ============================================================================
# 3. ASYNC DESTEÄžÄ° Ä°Ã‡Ä°N KÃœÃ‡ÃœK DEÄžÄ°ÅžÄ°KLÄ°KLER
# ============================================================================

"""
BazÄ± sync fonksiyonlarÄ± async yapmak gerekebilir. Ä°ÅŸte Ã¶rnekler:
"""

# Gemini API Ã§aÄŸrÄ±larÄ± zaten async ise sorun yok
# DiÄŸer sync fonksiyonlar iÃ§in:

async def run_transcript_pipeline_async(*args, **kwargs):
    """Wrapper to make sync pipeline async."""
    import asyncio

    # CPU-intensive iÅŸlemler iÃ§in thread pool kullan
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, run_transcript_pipeline_sync, *args, **kwargs)

def run_transcript_pipeline_sync(*args, **kwargs):
    """Mevcut sync pipeline'Ä±nÄ±z."""
    # Mevcut kodunuz burada kalÄ±r
    pass


# ============================================================================
# 4. ADVANCED: GRANÃœLEr MONÄ°TORÄ°NG (Ä°STEÄžE BAÄžLI)
# ============================================================================

"""
Daha detaylÄ± monitoring istiyorsanÄ±z, pipeline iÃ§inde context manager kullanÄ±n:
"""

from transcript_monitoring import TranscriptMonitor

async def advanced_transcript_pipeline(mp4_path: str, user_id: str, **kwargs):
    """Pipeline iÃ§inde detaylÄ± monitoring."""

    async with TranscriptMonitor(user_id=user_id, session_id=kwargs.get('meeting_id')) as monitor:

        # 1. Audio processing phase
        monitor.mark_audio_processing_start()
        monitor.add_audio_metadata(file_path=mp4_path)

        wav_path = await convert_mp4_to_wav(mp4_path)
        chunks = await split_wav_into_chunks_v2(wav_path)

        monitor.mark_audio_processing_end()

        # 2. Diarization phase
        monitor.add_custom_metadata(phase="diarization", chunk_count=len(chunks))

        diarized_chunks = await diarize_chunks_with_global_ids_union(chunks)

        # 3. Transcription phase
        monitor.mark_model_inference_start()
        monitor.add_custom_metadata(phase="transcription", model="whisper")

        transcribed_segments = await run_whisper_transcription(diarized_chunks)

        # 4. Correction phase (Gemini)
        monitor.add_custom_metadata(phase="correction", model="gemini")

        corrected_segments = await gemini_correct_and_infer_segments_async_v3(transcribed_segments)

        monitor.mark_model_inference_end()

        # Final result
        final_result = {
            "segments": corrected_segments,
            "total_duration": sum(s['duration'] for s in corrected_segments),
            "word_count": sum(len(s['text'].split()) for s in corrected_segments)
        }

        monitor.set_result(final_result)

        return final_result


# ============================================================================
# 5. Ã–RNEK KULLANIM - TEST EDÄ°N
# ============================================================================

async def test_monitoring_integration():
    """Test your monitoring integration."""

    # Simulate a request
    from app.schemas import TranscribeRequest

    test_request = TranscribeRequest(
        video_path="/path/to/test/video.mp4",
        user_id="test_user_123",
        meeting_id="meeting_456",
        attendees=["Alice", "Bob"]
    )

    print("ðŸŽ¬ Testing monitored transcription...")

    # Bu Ã§aÄŸrÄ± otomatik olarak monitor edilecek
    result = await transcribe_video(test_request)

    print(f"âœ… Result: {result}")

    # Monitoring stats'a bak
    import asyncio
    await asyncio.sleep(2)  # Background processing iÃ§in bekle

    stats = get_monitoring_stats()
    print(f"ðŸ“Š Monitoring stats: {stats}")


if __name__ == "__main__":
    import asyncio
    asyncio.run(test_monitoring_integration())


# ============================================================================
# 6. Ã–ZET - YAPMANIZ GEREKENLER
# ============================================================================

"""
âœ… CHECKLIST:

1. app/main.py'a import ekle:
   from transcript_monitoring import transcript_monitor, get_monitoring_stats, health_check

2. transcribe_video fonksiyonuna decorator ekle:
   @transcript_monitor(user_context=lambda request: request.user_id, ...)

3. app/pipeline/pipeline.py'da run_transcript_pipeline'a decorator ekle:
   @transcript_monitor(user_context=lambda **kw: kw.get('user_id'), ...)

4. FonksiyonlarÄ± async yap (gerekirse):
   async def run_transcript_pipeline(...)

5. .env'de ayarlarÄ± kontrol et:
   MONITORING_ENABLED=true
   SEND_TO_VERTEX=false (ilk test iÃ§in)
   MONITORING_OFFLINE_MODE=true

6. Test et:
   python integration_guide.py

TAMAM! ArtÄ±k mevcut pipeline'Ä±nÄ±z otomatik monitoring'e sahip! ðŸŽ‰
"""